{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce9fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sysp\n",
    "import sys,os\n",
    "\n",
    "from reion_uvlf_funcs import model_and_data\n",
    "\n",
    "sys.path.append('../../code/')\n",
    "from mountaineer import Model,Chi2,Mountaineer\n",
    "from paths import *\n",
    "\n",
    "sys.path.append(ML_Path)\n",
    "from mlalgos import BuildNN,Sequential\n",
    "\n",
    "sys.path.append(Picasa_Path)\n",
    "from gpr_train import GPRTrainer\n",
    "from picasa import PICASA\n",
    "\n",
    "import copy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as pltcol\n",
    "import gc\n",
    "\n",
    "from cobaya.run import run\n",
    "from cobaya.log import LoggedError\n",
    "from getdist.mcsamples import loadMCSamples\n",
    "import getdist.plots as gdplt\n",
    "\n",
    "pic = PICASA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080b18d1-4f4d-430b-8605-b31f1e641edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['xtick.top'] = True\n",
    "mpl.rcParams['ytick.right'] = True\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['legend.fontsize'] = 14 # 14\n",
    "mpl.rcParams['legend.labelspacing'] = 0.25\n",
    "FS = 18\n",
    "FS2 = 15\n",
    "FS3 = 13\n",
    "FSL = 22\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 6\n",
    "mpl.rcParams['xtick.minor.size'] = 3\n",
    "mpl.rcParams['ytick.major.size'] = 6\n",
    "mpl.rcParams['ytick.minor.size'] = 3\n",
    "\n",
    "#mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db445b3-1b85-4394-b851-0f3f1a502aa8",
   "metadata": {},
   "source": [
    "## Posterior Emulation with [Mountaineer](https://github.com/a-paranjape/mountaineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64a6a6-23f5-450d-9fbf-4e2a253d0f43",
   "metadata": {},
   "source": [
    "### UVLF & Reionization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2db8dd9-acc7-4574-8eb9-c602b5446943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UVLF_Reionization(Model):\n",
    "    def __init__(self,n_params=9):\n",
    "        Model.__init__(self,n_params=n_params)\n",
    "        self.dlntheta = 1e-4*np.ones(n_params) # should be much smaller than typical step-size in each direction\n",
    "        data,dum2,dum3 = model_and_data(-0.19, -0.92, 13.0, 2.1, 4.97, 0.34, -0.97, -0.41,9.32)\n",
    "        self.n_data = data.size\n",
    "\n",
    "    def calc_model(self,X):\n",
    "        lsum, ldiff, l2, l3, asum, adiff,  log10_fesc10, alpha_esc, log10Mcrit = self.params.T[0]\n",
    "        try:\n",
    "            out,dummy1,dummy2 = model_and_data(lsum, ldiff, l2, l3, asum, adiff,  log10_fesc10, alpha_esc, log10Mcrit)\n",
    "        except ValueError:\n",
    "            # print(\"Exception at parameters:\",self.params.T[0])\n",
    "            out = np.array([1e30]*self.n_data)\n",
    "            \n",
    "        self.model_fid = out.copy()\n",
    "        return self.rv(out[X[0]]) # X.shape = (1,n_samp)\n",
    "    \n",
    "    def calc_dmdtheta(self):\n",
    "        # self.X,self.model_fid will be available for the data set\n",
    "        dmdtheta = np.zeros((self.n_params,self.X.shape[1])) # (n_params,n_samp)\n",
    "        Dtheta = np.fabs(self.params.T[0])*self.dlntheta # Dtheta\n",
    "        switcher = np.ones(self.n_params)\n",
    "        u = np.random.rand(self.n_params)\n",
    "        switcher[u < 0.5] = -1.0\n",
    "        for p in range(self.n_params):\n",
    "            params_vary = self.params.T[0].copy()\n",
    "            params_vary[p] += switcher[p]*Dtheta[p] # theta +- Dtheta\n",
    "            lsum, ldiff, l2, l3, asum, adiff,  log10_fesc10, alpha_esc, log10Mcrit = params_vary\n",
    "            try:\n",
    "                model_vary,dum1,dum2 = model_and_data(lsum, ldiff, l2, l3, asum, adiff,  log10_fesc10, alpha_esc, log10Mcrit) \n",
    "                # M(theta +- Dtheta)\n",
    "            except ValueError:\n",
    "                # print(\"Exception at parameters:\",params_p)\n",
    "                model_vary = np.array([1e30]*self.n_data)\n",
    "            dmdtheta[p] = switcher[p]*(model_vary[self.X[0]] - self.model_fid[self.X[0]]) \n",
    "            # +- [ Model(theta +- Dtheta) - Model(theta) ]\n",
    "            # = +- Model(theta +- Dtheta) -+ Model(theta)\n",
    "            # ... = (+): Model(theta + Dtheta) - Model(theta)\n",
    "            # ... = (-): Model(theta) - Model(theta - Dtheta)\n",
    "\n",
    "        dmdtheta = dmdtheta.T\n",
    "        dmdtheta /= (Dtheta + 1e-15)\n",
    "        dmdtheta = dmdtheta.T\n",
    "        \n",
    "        return dmdtheta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f5c4c-bb57-488a-91ca-8167041db30e",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4a76da-a44d-4444-ab4e-02f1e1ddc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bf6899-e159-4450-aa9b-194b9ef00856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_str: reion_lgNmax3.00\n"
     ]
    }
   ],
   "source": [
    "# rng = np.random.RandomState(1983)\n",
    "pbest_cobaya = np.array([-4.8750e-01,-8.8095e-01,1.0735e+01,1.2034e+00,9.4376e-01,2.8934e-01,-8.1220e-01,-7.8249e-02,1.0174e+01])\n",
    "\n",
    "N_evals_max = 1000 # MCMC needed 558703 total steps, 69840 accepted.\n",
    "id_str = 'reion' \n",
    "survey_frac = 0.025 # 0.05\n",
    "\n",
    "model = UVLF_Reionization()\n",
    "\n",
    "dummy,data,sigma = model_and_data(-0.19, -0.92, 13.0, 2.1, 4.97, 0.34, -0.97, -0.41,9.32)\n",
    "\n",
    "X_all = np.arange(data.size)\n",
    "n_samp = X_all.size\n",
    "X_all = model.rv(X_all)\n",
    "\n",
    "n_params = model.n_params\n",
    "cov_mat = np.diag(sigma**2)\n",
    "Y_all = model.rv(data)\n",
    "\n",
    "dof = X_all.shape[1] - n_params\n",
    "\n",
    "# id_str += '_lgNmax{0:.2f}_defAdam'.format(np.log10(N_evals_max))\n",
    "id_str += '_lgNmax{0:.2f}'.format(np.log10(N_evals_max))\n",
    "if Narrow:\n",
    "    id_str += '_narrow'\n",
    "print('id_str:',id_str)\n",
    "file_stem = 'walks/' + id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9aa728-8e31-449a-8c98-4b1f6f03d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mountaineer to explore loss land-scape!\n",
      "... initialization done\n"
     ]
    }
   ],
   "source": [
    "Walks_Exist = False\n",
    "\n",
    "if Narrow:\n",
    "    param_mins = [-2.0,-1.5,8.0,2.0,0.0,0.2,-1.0,-1.0,9.0]\n",
    "    param_maxs = [ 0.0,-0.5,12.0,5.0,3.0,0.8,0.5,0.5,10.0]\n",
    "else:\n",
    "    param_mins = [-2.0,-2.0,8.0,0.5,0.0,0.0,-3.0,-3.0,9.0]\n",
    "    param_maxs = [ 2.0, 1.0,18.0,6.0,7.0,1.0,1.0,1.0,11.0]\n",
    "\n",
    "loss_params = {'cov_mat':cov_mat}\n",
    "\n",
    "dp = {'N_evals_max':N_evals_max,'survey_frac':survey_frac,'file_stem':file_stem,'model':UVLF_Reionization,'n_params':n_params,\n",
    "      'param_mins':param_mins,'param_maxs':param_maxs,\n",
    "      'X':X_all,'Y':Y_all,'val_frac':0.2,'loss':Chi2,'walks_exist':Walks_Exist,\n",
    "      'seed':None,'verbose':True,'logfile':None,'loss_params':loss_params}\n",
    "\n",
    "mnt = Mountaineer(data_pack=dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5804feb-b42e-47a8-a195-6366c70a521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surveying using 25 locations 5 times...\n",
      "... iteration 1\n",
      "... creating survey\n",
      "... ... evaluating loss values and gradients\n",
      "[....................] 100% done\n",
      "... ... excluding NaNs\n",
      "... ... kept 25 of 25 surveyed points\n",
      "... adjusting survey\n",
      "... ... looping through layers\n",
      "... ... avg div(grad loss) negative at layer 0; breaking.\n",
      "... ... adjusting parameter ranges\n",
      "... ... Dtheta_loss: [2.109e+01,1.775e-01,3.303e+01,6.812e+00,2.890e+02,2.310e-01,2.366e-01,1.878e-01,3.681e-01]\n",
      "... iteration 2\n",
      "... creating survey\n",
      "... ... evaluating loss values and gradients\n",
      "[....................] 100% done\n",
      "... ... excluding NaNs\n",
      "... ... kept 25 of 25 surveyed points\n",
      "... adjusting survey\n",
      "... ... looping through layers\n",
      "... ... avg div(grad loss) negative at layer 12; breaking.\n",
      "... ... no adjustment needed (probably!)\n",
      "... ... Dtheta_loss: [2.272e+01,2.641e+01,3.560e+01,1.300e+01,2.923e+02,1.984e+00,1.157e+01,4.048e+01,8.021e+01]\n",
      "... iteration 3\n",
      "... creating survey\n",
      "... ... evaluating loss values and gradients\n",
      "[....................] 100% done\n",
      "... ... excluding NaNs\n",
      "... ... kept 25 of 25 surveyed points\n",
      "... adjusting survey\n",
      "... ... looping through layers\n",
      "... ... avg div(grad loss) negative at layer 2; breaking.\n",
      "... ... adjusting parameter ranges\n",
      "... ... Dtheta_loss: [3.461e+01,2.754e+01,4.349e+01,2.159e+01,3.615e+02,5.048e+00,1.444e+01,4.335e+01,8.135e+01]\n",
      "... iteration 4\n",
      "... creating survey\n",
      "... ... evaluating loss values and gradients\n",
      "[....................] 100% done\n",
      "... ... excluding NaNs\n",
      "... ... kept 25 of 25 surveyed points\n",
      "... adjusting survey\n",
      "... ... looping through layers\n",
      "... ... avg div(grad loss) negative at layer 3; breaking.\n",
      "... ... adjusting parameter ranges\n",
      "... ... Dtheta_loss: [4.141e+01,2.824e+01,4.666e+01,2.453e+01,3.681e+02,5.712e+00,2.556e+01,5.494e+01,1.327e+02]\n",
      "... iteration 5\n",
      "... creating survey\n",
      "... ... evaluating loss values and gradients\n",
      "[....................] 100% done\n",
      "... ... excluding NaNs\n",
      "... ... kept 25 of 25 surveyed points\n",
      "... adjusting survey\n",
      "... ... looping through layers\n",
      "... ... avg div(grad loss) negative at layer 3; breaking.\n",
      "... ... adjusting parameter ranges\n",
      "... ... Dtheta_loss: [8.529e+01,2.935e+01,1.188e+02,5.162e+01,4.171e+02,6.352e+00,2.871e+01,5.821e+01,1.351e+02]\n",
      "... eliminated 4 repeated param vectors\n",
      "... old param_mins  = [-2.00e+00,-2.00e+00,8.00e+00,5.00e-01,0.00e+00,0.00e+00,-3.00e+00,-3.00e+00,9.00e+00]\n",
      "... ... modified to = [-1.68e+00,-1.76e+00,8.80e+00,9.40e-01,5.60e-01,8.00e-02,-2.68e+00,-2.68e+00,9.16e+00]\n",
      "... old param_maxs  = [2.00e+00,1.00e+00,1.80e+01,6.00e+00,7.00e+00,1.00e+00,1.00e+00,1.00e+00,1.10e+01]\n",
      "... ... modified to = [1.68e+00,7.60e-01,1.72e+01,5.56e+00,6.44e+00,9.20e-01,6.80e-01,6.80e-01,1.08e+01]\n",
      "Distributing available resources (875 evals)...\n",
      "... initialising 27 walkers\n",
      "... setting up training parameters\n",
      "... ...   max_epoch = 16\n",
      "... ...    mb_count = 2\n",
      "... ... check_after = 5\n",
      "... ...      lrates (outside inwards)\n",
      "... ... ...    p0 : 0.5110 to 0.4732\n",
      "... ... ...    p1 : 0.2596 to 0.2404\n",
      "... ... ...    p2 : 0.9537 to 0.8831\n",
      "... ... ...    p3 : 0.4662 to 0.4316\n",
      "... ... ...    p4 : 1.4949 to 1.3842\n",
      "... ... ...    p5 : 0.0697 to 0.0646\n",
      "... ... ...    p6 : 0.2965 to 0.2745\n",
      "... ... ...    p7 : 0.4222 to 0.3909\n",
      "... ... ...    p8 : 0.4548 to 0.4211\n",
      "... ...    B1_adams = 0.900 to 0.010 (outside inwards)\n",
      "... ...  1-B2_adams = 1.00e-03 to 1.00e-06 (outside inwards)\n",
      "Climbing...\n",
      "[..                  ] 11% done"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "walks = mnt.explore()\n",
    "mnt.time_this(start_time)\n",
    "mnt.visualize(walks)\n",
    "data = mnt.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70947a2b-6c73-45c2-9365-889a27ca40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibest = np.argmin(data[0])\n",
    "chi2_best = data[0,ibest]\n",
    "pbest = data[1:,ibest].copy()  \n",
    "\n",
    "print(chi2_best)\n",
    "print(pbest)\n",
    "print(pbest_cobaya)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c998768-e510-4514-aab5-c0a5d50eee4d",
   "metadata": {},
   "source": [
    "## Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f027c-ca03-4a8f-b4b9-eb11fb00d08c",
   "metadata": {},
   "source": [
    "### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef0770-86dd-48ed-be73-228dc86cdecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPR_Exists = Walks_Exist\n",
    "CV_Thresh = 1e-3 \n",
    "GPR_Dir = 'gpr/stats_'+id_str\n",
    "gprt = GPRTrainer(data_file=mnt.walks_file,tmp_dir=GPR_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e04e96-bf1e-4fdb-9d05-66c600492d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "Kernel = 'matern' \n",
    "Max_Iter = 25 \n",
    "if GPR_Exists:\n",
    "    interpolator = gprt.train_gpr(verbose=True,vary_kernel=False,kernel=Kernel,skip_train=True)\n",
    "else:\n",
    "    interpolator = gprt.train_gpr(cv_thresh=CV_Thresh,verbose=True,vary_kernel=True,max_iter=Max_Iter,max_iter_vary=Max_Iter//5)\n",
    "gprt.time_this(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865d62c-98fd-4975-8b25-0e7b70333dd6",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a93662-81f2-487f-8f96-ee1e6e169ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = data[1:,:]\n",
    "Yp = mnt.rv(data[0])\n",
    "print(Xp.shape,Yp.shape,mnt.n_params)\n",
    "\n",
    "# trim\n",
    "print('Trimming training data...')\n",
    "keep_these = np.ones(Yp.shape[1],dtype=bool)\n",
    "for p in range(Xp.shape[0]):\n",
    "    keep_these = keep_these & (Xp[p] >= mnt.param_mins[p]) & (Xp[p] <= mnt.param_maxs[p])\n",
    "print('... keeping {0:d} of {1:d}'.format(np.where(keep_these)[0].size,keep_these.size))\n",
    "\n",
    "Xp = Xp[:,keep_these]\n",
    "Yp = Yp[:,keep_these]\n",
    "print(Xp.shape,Yp.shape,mnt.n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a2552-1dea-425f-be78-c57c8ea0937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[n_params**2,2*n_params**2,3*n_params**2,4*n_params**2,5*n_params**2,6*n_params**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d6bb5-1f01-4427-9d8e-679181e615a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Build = not Walks_Exist\n",
    "\n",
    "Train_Frac = 0.8 \n",
    "Val_Frac = 0.2\n",
    "Arch_Type = 'emulator:deep'\n",
    "Min_Layer = 1\n",
    "Max_Layer = 3\n",
    "Max_Ex = [n_params,2*n_params,4*n_params] #[3*n_params**2,4*n_params**2]\n",
    "LRates = [1e-4,3e-4] # [3e-4] # None or list of floats\n",
    "Wt_Decays = [0.0] # non-empty list\n",
    "N_Iter = 15\n",
    "TTL = 1e-3\n",
    "Loss_Type = 'square'\n",
    "Seed = None\n",
    "FileStem = 'net/NN_'+id_str\n",
    "\n",
    "start_time = time()\n",
    "bnn = BuildNN(Xp,Yp,train_frac=Train_Frac,arch_type=Arch_Type,max_ex=Max_Ex,min_layer=Min_Layer,max_layer=Max_Layer,thresholds=None,\n",
    "              val_frac=Val_Frac,n_iter=N_Iter,wt_decays=Wt_Decays,lrates=LRates,\n",
    "              target_test_stat=TTL,loss_type=Loss_Type,seed=Seed,file_stem=FileStem)\n",
    "if Build:\n",
    "    net,params_train,mtl = bnn.trainNN()\n",
    "    print('Best mean test loss = {0:.3e}'.format(mtl))\n",
    "    print('Setup params: ',net.params)\n",
    "    print('Training params: ',params_train)\n",
    "else:\n",
    "    net = bnn.load()\n",
    "    print('Loaded network with')\n",
    "    print('...    setup params: ',net.params)\n",
    "    params_train = bnn.load_train()\n",
    "    print('... training params: ',params_train)\n",
    "\n",
    "print('No. of free params optimized = {0:d}\\n'.format(net.calc_N_freeparams()))\n",
    "bnn.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64086eb8-32e9-4efc-bead-89ba9c092052",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Build:#Train:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.xlim(0.5,2*params_train['max_epoch'])\n",
    "    # plt.ylim(1e-4,1e7)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    nn_label = '{0:1d}-layer NN'.format(net.L)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(net.epochs,net.epoch_loss,'k-',lw=0.5,label=nn_label+': train')\n",
    "    plt.plot(net.epochs,net.val_loss,'r-',lw=0.5,label=nn_label+': val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(net.epoch_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ccb72-622f-4cb4-a71e-684303914037",
   "metadata": {},
   "source": [
    "### Testing emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482ebdb-810d-4c4b-ba37-9cd4356a3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True loss calculation')\n",
    "start_time = time()\n",
    "Nsamp_ev = 300#0\n",
    "Xp_ev = mnt.gen_latin_hypercube(Nsamp=Nsamp_ev,dim=mnt.n_params,param_mins=mnt.param_mins,param_maxs=mnt.param_maxs)\n",
    "Yp_ev = np.zeros((1,Nsamp_ev))\n",
    "loss_params_ev = copy.deepcopy(loss_params)\n",
    "loss_params_ev['Y_full'] = mnt.Y\n",
    "for n in range(Nsamp_ev):\n",
    "    # model.params[:,0] = Xp_ev[n]\n",
    "    model.params[:,0] = Xp_ev[n]\n",
    "    Loss_ev = mnt.loss_module(loss_params_ev)\n",
    "    Yp_ev[0,n] = Loss_ev.forward(model.calc_model(mnt.X))\n",
    "    mnt.status_bar(n,Nsamp_ev)\n",
    "Xp_ev = Xp_ev.T\n",
    "mnt.time_this(start_time)\n",
    "\n",
    "# print('NN prediction for loss')\n",
    "# start_time = time()\n",
    "# Yp_ev_pred_nn = net.predict(Xp_ev)\n",
    "# mnt.time_this(start_time)\n",
    "\n",
    "# resid_nn = Yp_ev_pred_nn[0]/Yp_ev[0] - 1\n",
    "\n",
    "print('GPR prediction for loss')\n",
    "start_time = time()\n",
    "Yp_ev_pred_gpr = gprt.predict(Xp_ev.T,interpolator)\n",
    "mnt.time_this(start_time)\n",
    "\n",
    "resid_gpr = Yp_ev_pred_gpr/Yp_ev[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07511e1e-ff21-430e-ac8b-f3d5b6d3954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.xlabel('true loss')\n",
    "plt.ylabel('predicted / true - 1')\n",
    "plt.ylim(-1,1)\n",
    "# plt.scatter(Yp_ev[0],resid_nn,s=0.8,color='r',label='NN')\n",
    "plt.scatter(Yp_ev[0],resid_gpr,s=0.8,color='b',label='GPR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('true loss')\n",
    "plt.ylabel('predicted loss')\n",
    "plt.plot(np.logspace(2.0,6.5,10),np.logspace(2.0,6.5,10),'k--',lw=1)\n",
    "# plt.scatter(Yp_ev[0],Yp_ev_pred_nn[0],s=0.8,color='r',label='NN')\n",
    "plt.scatter(Yp_ev[0],Yp_ev_pred_gpr,s=0.8,color='b',label='GPR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882f42f-58e3-4c06-b99e-ac508047384b",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a8d42-8d2a-4f95-a80f-f8d0c8aa86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Like_Dir = '../../code/likes/'\n",
    "Plots_Dir = 'plots/'\n",
    "\n",
    "Run_Cobaya = False\n",
    "Run_NN = False\n",
    "Run_GPR = True\n",
    "\n",
    "Max_Samples = 1000000\n",
    "Rminus1_Stop = 0.01\n",
    "Rminus1_CL_Stop = 0.05 # 0.05\n",
    "Rminus1_CL_Level = 0.95 # 95\n",
    "\n",
    "Burn_In = 0\n",
    "\n",
    "gd_sample = loadMCSamples(os.path.abspath('cobaya_chains/chains/reion_uvlf_9p'))\n",
    "Latex_List = gd_sample.paramNames.labels()[:mnt.n_params]\n",
    "Params_List = gd_sample.paramNames.list()[:mnt.n_params]\n",
    "print(Latex_List)\n",
    "print(Params_List)\n",
    "# Latex_List = [\"a_{{{0:d}}}\".format(p) for p in range(n_params)]\n",
    "# Params_List = [\"a{0:d}\".format(p) for p in range(n_params)]\n",
    "\n",
    "info = {}\n",
    "info['params'] = {}\n",
    "# info['likelihood'] = {'likelihoods.Chi2Like':\n",
    "#                       {'python_path':Like_Dir,\n",
    "#                        'X':X_all,'Y':Y_all,'cov_mat':cov_mat}}\n",
    "# info['theory'] = {'examplelikes.PowSineTheory':\n",
    "#                   {'python_path':Like_Dir,\n",
    "#                    'X':X_all}}\n",
    "for p in range(len(Params_List)):\n",
    "    ref = pbest[p] #0.5*(mnt.param_mins[p] + mnt.param_maxs[p])\n",
    "    info['params'][Params_List[p]] = {'ref':{'min':ref-0.0005,'max':ref+0.0005},\n",
    "                                      'prior':{'min':mnt.param_mins[p],'max':mnt.param_maxs[p]},\n",
    "                                      'proposal':0.005,'latex':Latex_List[p]}\n",
    "\n",
    "info['sampler'] = {'mcmc':\n",
    "                   {'learn_proposal': True,\n",
    "                    'Rminus1_single_split': 4,\n",
    "                    'measure_speeds': True,\n",
    "                    'max_samples': Max_Samples,\n",
    "                    'max_tries': 10000,\n",
    "                    'Rminus1_stop': Rminus1_Stop,\n",
    "                    'Rminus1_cl_stop': Rminus1_CL_Stop,\n",
    "                    'Rminus1_cl_level': Rminus1_CL_Level,\n",
    "                    'burn_in': Burn_In}}\n",
    "info_output = 'stats/chains/'+id_str\n",
    "info['output'] = info_output\n",
    "info[\"force\"] = True    \n",
    "\n",
    "if Run_NN:\n",
    "    info_nn = copy.deepcopy(info)\n",
    "    info_nn['likelihood'] = {'likelihoods.EmulLike':\n",
    "                             {'python_path':Like_Dir}}\n",
    "    info_nn['theory'] = {'likelihoods.NNTheory':\n",
    "                             {'python_path':Like_Dir,\n",
    "                              'net':net,'keys':Params_List}}\n",
    "    info_nn['output'] = info_output+'_nn'\n",
    "\n",
    "if Run_GPR:\n",
    "    info_gpr = copy.deepcopy(info)\n",
    "    info_gpr['likelihood'] = {'likelihoods.EmulLike':\n",
    "                                 {'python_path':Like_Dir}}\n",
    "    info_gpr['theory'] = {'likelihoods.GPRTheory':\n",
    "                             {'python_path':Like_Dir,\n",
    "                              'gprt':gprt,'interpolator':interpolator,'keys':Params_List}}\n",
    "    info_gpr['output'] = info_output+'_gpr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0421e-1d3b-4357-9d38-2e178d093b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_Cobaya:\n",
    "    start_time = time()\n",
    "    updated_info, sampler = run(info)\n",
    "    Neval_cobaya = pic.calc_Neval(sampler)\n",
    "    print('Neval_cobaya = {0:d}'.format(Neval_cobaya))\n",
    "    mnt.time_this(start_time)\n",
    "else:\n",
    "    Neval_cobaya = 558703\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44170b-62f4-414d-9342-f2345ad80ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_NN:\n",
    "    start_time = time()\n",
    "    updated_info_nn, sampler_nn = run(info_nn)\n",
    "    Neval_nn = pic.calc_Neval(sampler_nn)\n",
    "    print('Neval_nn = {0:d}'.format(Neval_nn))\n",
    "    mnt.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e90d9-5e92-4547-ac45-3a869b2aa48f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Run_GPR:\n",
    "    start_time = time()\n",
    "    updated_info_gpr, sampler_gpr = run(info_gpr)\n",
    "    Neval_gpr = pic.calc_Neval(sampler_gpr)\n",
    "    print('Neval_gpr = {0:d}'.format(Neval_gpr))\n",
    "    mnt.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312805d0-fddd-49a3-b1a9-0c959f375408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Fig = False\n",
    "\n",
    "Show_MCMC = True\n",
    "Show_NN = False\n",
    "Show_GPR = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2e126-8a9a-46e1-8179-7c2589387548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Burn_Frac = 0.3\n",
    "rng = np.random.RandomState(42)\n",
    "dim = n_params\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "if Show_MCMC:\n",
    "    gd_sample = loadMCSamples(os.path.abspath('cobaya_chains/chains/reion_uvlf_9p'),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample.label = 'MCMC: {0:d} evals'.format(Neval_cobaya) \n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat = gd_sample.getCovMat().matrix[:dim, :dim]\n",
    "    sample = gd_sample.samples\n",
    "    sample = sample.T\n",
    "    ibest = sample[-2].argmin()\n",
    "    mcmc_best = sample[:dim,ibest]\n",
    "    mcmc_chi2 = sample[-2,ibest]\n",
    "    pval = sysp.gammainc(mcmc_chi2/2,dof/2)\n",
    "    mcmc_sig = np.sqrt(np.diag(mcmc_covmat))\n",
    "    print('MCMC...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_best])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2,dof,mcmc_chi2/dof,pval))\n",
    "\n",
    "if Show_NN:\n",
    "    gd_sample_nn = loadMCSamples(os.path.abspath(info_nn[\"output\"]),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample_nn.label = '     NN: {0:d} of {1:d} evals'.format(Xp.shape[1],keep_these.size)\n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat_nn = gd_sample_nn.getCovMat().matrix[:dim, :dim]\n",
    "    sample_nn = gd_sample_nn.samples\n",
    "    sample_nn = sample_nn.T\n",
    "    ibest_nn = sample_nn[-2].argmin()\n",
    "    mcmc_best_nn = sample_nn[:dim,ibest_nn]\n",
    "    mcmc_chi2_nn = sample_nn[-2,ibest_nn]\n",
    "    pval_nn = sysp.gammainc(mcmc_chi2_nn/2,dof/2)\n",
    "    mcmc_sig_nn = np.sqrt(np.diag(mcmc_covmat_nn))\n",
    "    print('NN...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_best_nn])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_nn])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_nn,dof,mcmc_chi2_nn/dof,pval_nn))\n",
    "\n",
    "if Show_GPR:\n",
    "    gd_sample_gpr = loadMCSamples(os.path.abspath(info_gpr[\"output\"]),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample_gpr.label = '   GPR: {0:d} evals'.format(gprt.pred_var.size)\n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat_gpr = gd_sample_gpr.getCovMat().matrix[:dim, :dim]\n",
    "    sample_gpr = gd_sample_gpr.samples\n",
    "    sample_gpr = sample_gpr.T\n",
    "    ibest_gpr = sample_gpr[-2].argmin()\n",
    "    mcmc_best_gpr = sample_gpr[:dim,ibest_gpr]\n",
    "    mcmc_chi2_gpr = sample_gpr[-2,ibest_gpr]\n",
    "    pval_gpr = sysp.gammainc(mcmc_chi2_gpr/2,dof/2)\n",
    "    mcmc_sig_gpr = np.sqrt(np.diag(mcmc_covmat_gpr))\n",
    "    print('GPR...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_best_gpr])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_gpr])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_gpr,dof,mcmc_chi2_gpr/dof,pval_gpr))\n",
    "\n",
    "plot_param_list = Params_List\n",
    "Subplot_Size = 1.6 \n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter(subplot_size=Subplot_Size)\n",
    "gdplot.settings.num_plot_contours = 3\n",
    "gdplot.settings.axes_fontsize = FS3\n",
    "gdplot.settings.axes_labelsize = FS2\n",
    "gdplot.settings.title_limit_fontsize = FS3\n",
    "\n",
    "show_list = []\n",
    "fill_list = []\n",
    "col_list = []\n",
    "if Show_MCMC:\n",
    "    show_list.append(gd_sample)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('indigo')\n",
    "    # gdplot.triangle_plot(gd_sample,gd_sample.paramNames.list()[:dim],contour_colors=['indigo'],legend_loc='upper right',title_limit=0)\n",
    "if Show_NN:\n",
    "    show_list.append(gd_sample_nn)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('crimson')\n",
    "if Show_GPR:\n",
    "    show_list.append(gd_sample_gpr)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('darkgreen')\n",
    "gdplot.triangle_plot(show_list, plot_param_list,filled=fill_list,\n",
    "                     contour_colors=col_list,legend_loc='upper right',\n",
    "                     title_limit=0)\n",
    "for par_y in range(dim):\n",
    "    str_y = plot_param_list[par_y]\n",
    "    ax = gdplot.subplots[par_y,par_y]\n",
    "    if Show_MCMC:\n",
    "        ax.axvline(mcmc_best[par_y],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "    if Show_NN:\n",
    "        ax.axvline(mcmc_best_nn[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "    if Show_GPR:\n",
    "        ax.axvline(mcmc_best_gpr[par_y],c='darkgreen',ls='--',lw=1,alpha=0.6)\n",
    "    for par_x in range(par_y):\n",
    "        str_x = plot_param_list[par_x]\n",
    "        #print(par_x,par_y,':',str_x,str_y)\n",
    "        ax = gdplot.subplots[par_y,par_x]\n",
    "        if Show_MCMC:\n",
    "            ax.scatter([mcmc_best[par_x]],[mcmc_best[par_y]],marker='*',s=50,c='aliceblue')\n",
    "            ax.axvline(mcmc_best[par_x],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_best[par_y],c='indigo',ls='--',lw=1.5,alpha=0.6)\n",
    "        if Show_NN:\n",
    "            ax.scatter([mcmc_best_nn[par_x]],[mcmc_best_nn[par_y]],marker='*',s=50,c='peachpuff')\n",
    "            ax.axvline(mcmc_best_nn[par_x],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_best_nn[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "        if Show_GPR:\n",
    "            ax.scatter([mcmc_best_gpr[par_x]],[mcmc_best_gpr[par_y]],marker='*',s=50,c='lightcyan')\n",
    "            ax.axvline(mcmc_best_gpr[par_x],c='darkgreen',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_best_gpr[par_y],c='darkgreen',ls='--',lw=1,alpha=0.6)\n",
    "\n",
    "if Save_Fig:\n",
    "    filename = 'contours_'+id_str+'.png'\n",
    "    print('Writing to file: '+Plots_Dir+filename)\n",
    "    gdplot.export(fname=filename,adir=Plots_Dir)\n",
    "\n",
    "mnt.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09a274-ba0e-4137-95cc-86e306b4b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "N_BOOT = 100\n",
    "# MCMC\n",
    "if Show_MCMC:\n",
    "    model.params = mnt.cv(mcmc_best[:dim])\n",
    "    model_best = model.forward(mnt.X)[0]\n",
    "    \n",
    "    N_Boot_Cobaya = np.min([N_BOOT,int(0.2*sample[0].size)])\n",
    "    Ind = gd_sample.random_single_samples_indices(random_state=42,max_samples=N_Boot_Cobaya)\n",
    "    N_Boot_Cobaya = Ind.size\n",
    "    print('N_Boot_Cobaya: ',N_Boot_Cobaya)\n",
    "    \n",
    "    model_boot = np.zeros((N_Boot_Cobaya,n_samp),dtype=float)\n",
    "    \n",
    "    print('... extracting stats from subsample')\n",
    "    for b in range(N_Boot_Cobaya):\n",
    "        params_b = sample[:dim,Ind[b]] \n",
    "        model.params = mnt.cv(params_b[:dim])\n",
    "        model_boot[b] = model.forward(mnt.X)[0]\n",
    "        mnt.status_bar(b,N_Boot_Cobaya)\n",
    "    \n",
    "    model_16pc = np.percentile(model_boot,16,axis=0)\n",
    "    model_84pc = np.percentile(model_boot,84,axis=0)\n",
    "\n",
    "    del model_boot\n",
    "    gc.collect()\n",
    "\n",
    "# NN\n",
    "if Show_NN:\n",
    "    model.params = mnt.cv(mcmc_best_nn[:dim])\n",
    "    model_best_nn = model.forward(mnt.X)[0]\n",
    "    \n",
    "    N_Boot_NN = np.min([N_BOOT,int(0.2*sample_nn[0].size)])\n",
    "    Ind_nn = gd_sample_nn.random_single_samples_indices(random_state=42,max_samples=N_Boot_NN)\n",
    "    N_Boot_NN = Ind_nn.size\n",
    "    print('N_Boot_NN: ',N_Boot_NN)\n",
    "    \n",
    "    model_boot_nn = np.zeros((N_Boot_NN,n_samp),dtype=float)\n",
    "    \n",
    "    print('... extracting stats from subsample')\n",
    "    for b in range(N_Boot_NN):\n",
    "        params_b = sample_nn[:dim,Ind_nn[b]] \n",
    "        model.params = mnt.cv(params_b[:dim])\n",
    "        model_boot_nn[b] = model.forward(mnt.X)[0]\n",
    "        mnt.status_bar(b,N_Boot_NN)\n",
    "    \n",
    "    model_16pc_nn = np.percentile(model_boot_nn,16,axis=0)\n",
    "    model_84pc_nn = np.percentile(model_boot_nn,84,axis=0)\n",
    "\n",
    "    del model_boot_nn\n",
    "    gc.collect()\n",
    "\n",
    "# GPR\n",
    "if Show_GPR:\n",
    "    model.params = mnt.cv(mcmc_best_gpr[:dim])\n",
    "    model_best_gpr = model.forward(mnt.X)[0]\n",
    "    \n",
    "    N_Boot_GPR = np.min([N_BOOT,int(0.2*sample_gpr[0].size)])\n",
    "    Ind_gpr = gd_sample_gpr.random_single_samples_indices(random_state=42,max_samples=N_Boot_GPR)\n",
    "    N_Boot_GPR = Ind_gpr.size\n",
    "    print('N_Boot_GPR: ',N_Boot_GPR)\n",
    "    \n",
    "    model_boot_gpr = np.zeros((N_Boot_GPR,n_samp),dtype=float)\n",
    "    \n",
    "    print('... extracting stats from subsample')\n",
    "    for b in range(N_Boot_GPR):\n",
    "        params_b = sample_gpr[:dim,Ind_gpr[b]] \n",
    "        model.params = mnt.cv(params_b[:dim])\n",
    "        model_boot_gpr[b] = model.forward(mnt.X)[0]\n",
    "        mnt.status_bar(b,N_Boot_GPR)\n",
    "    \n",
    "    model_16pc_gpr = np.percentile(model_boot_gpr,16,axis=0)\n",
    "    model_84pc_gpr = np.percentile(model_boot_gpr,84,axis=0)\n",
    "\n",
    "    del model_boot_gpr\n",
    "    gc.collect()\n",
    "\n",
    "cols = ['indigo','crimson','darkgreen']\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(1e-7,10)\n",
    "plt.yscale('log')\n",
    "if Show_MCMC:\n",
    "    plt.plot(mnt.X[0],model_best,'-',lw=1,c=cols[0],label='MCMC')\n",
    "    plt.fill_between(mnt.X[0],model_84pc,model_16pc,color=cols[0],alpha=0.15)\n",
    "if Show_NN:\n",
    "    plt.plot(mnt.X[0],model_best_nn,'-',lw=1,c=cols[1],label='NN')\n",
    "    plt.fill_between(mnt.X[0],model_84pc_nn,model_16pc_nn,color=cols[1],alpha=0.15)\n",
    "if Show_GPR:\n",
    "    plt.plot(mnt.X[0],model_best_gpr,'-',lw=1,c=cols[2],label='GPR')\n",
    "    plt.fill_between(mnt.X[0],model_84pc_gpr,model_16pc_gpr,color=cols[2],alpha=0.15)\n",
    "\n",
    "plt.errorbar(mnt.X[0],mnt.Y[0],yerr=sigma,c='k',ls='none',capsize=5,marker='o',markersize=4,label='data')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.minorticks_on()\n",
    "if Save_Fig:\n",
    "    filename = Plots_Dir+'stats_'+id_str+'.png'\n",
    "    print('Writing to file: '+filename)\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "mnt.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c25d5b-e43f-48c8-8a06-2494ed276b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6a350-bc4b-498d-8449-91e7a73c0510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2783a2b-8921-4fb2-96b2-8ebd19a8e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train = False if Narrow else True\n",
    "# FileStem = 'net/NN_'+id_str\n",
    "# Seed = None #if Model_Type == 'ps' else 42\n",
    "\n",
    "# # N_L = 12+1 # 4,8,12,16,20\n",
    "# # Delta = 7\n",
    "# # HLay = [n_params + Delta]*(N_L - 1)\n",
    "# #########\n",
    "# # * = narrow, & = full\n",
    "# N_L = 3 if Narrow else 3 # 2,3*&,4\n",
    "# Fac = 70 if Narrow else 90 # 30,50,70*,90&,120\n",
    "# HLay = [Fac*n_params]*(N_L - 1)\n",
    "# HType = 'tanh' if Narrow else 'tanh' # 'tanh'*&, 'relu'\n",
    "# Wt_Decay = 0.0 # 0.0*&,0.3\n",
    "# LRate = 1e-5 if Narrow else 1e-5 # 1e-5*&,1e-4\n",
    "# Max_Epoch = 100000#0\n",
    "# Check_After = 300 if Narrow else 100 # 300*,100&? \n",
    "# Reg_Fun = 'none' \n",
    "\n",
    "# params_setup = {'data_dim':Xp.shape[0],'L':N_L,'n_layer':HLay+[1],'seed':Seed,'standardize':True,\n",
    "#                 'reg_fun':Reg_Fun,'wt_decay':Wt_Decay,\n",
    "#                 'atypes':[HType]*(N_L-1)+['lin'],'loss_type':'square','file_stem':FileStem}\n",
    "# params_train = {'lrate':LRate,'max_epoch':Max_Epoch,'mb_count':int(np.sqrt(0.8*Xp.shape[1])),'check_after':Check_After}\n",
    "#                 #,'val_frac':Val_Frac}    \n",
    "# net = Sequential(params_setup)\n",
    "# if Train:\n",
    "#     start_time = time()\n",
    "#     net.train(Xp,Yp,params_train)\n",
    "#     net.save()\n",
    "#     print('... trained network with setup params: ',net.params)\n",
    "#     net.time_this(start_time)\n",
    "# else:\n",
    "#     net.load()\n",
    "#     print('Loaded network with setup params: ',net.params)\n",
    "# print('No. of free params optimized = {0:d}\\n'.format(net.calc_N_freeparams()))\n",
    "# print ('... done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
