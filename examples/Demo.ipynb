{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sysp\n",
    "import sys,os\n",
    "\n",
    "sys.path.append('../')\n",
    "from mountaineer import Model,Chi2,Mountaineer\n",
    "\n",
    "sys.path.append('/home/aseem/python_modules/MachineLearning/mlfundas/code/')\n",
    "from mlalgos import BuildNN,Sequential\n",
    "\n",
    "sys.path.append('../../picasa/code/')\n",
    "from gpr_train import GPRTrainer\n",
    "from picasa import PICASA\n",
    "\n",
    "import copy\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as pltcol\n",
    "import gc\n",
    "\n",
    "from cobaya.run import run\n",
    "from cobaya.log import LoggedError\n",
    "from getdist.mcsamples import loadMCSamples\n",
    "import getdist.plots as gdplt\n",
    "\n",
    "pic = PICASA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b18d1-4f4d-430b-8605-b31f1e641edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['xtick.top'] = True\n",
    "mpl.rcParams['ytick.right'] = True\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['legend.fontsize'] = 14 # 14\n",
    "mpl.rcParams['legend.labelspacing'] = 0.25\n",
    "FS = 18\n",
    "FS2 = 15\n",
    "FS3 = 13\n",
    "FSL = 22\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 6\n",
    "mpl.rcParams['xtick.minor.size'] = 3\n",
    "mpl.rcParams['ytick.major.size'] = 6\n",
    "mpl.rcParams['ytick.minor.size'] = 3\n",
    "\n",
    "#mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db445b3-1b85-4394-b851-0f3f1a502aa8",
   "metadata": {},
   "source": [
    "## Testing Posterior Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64a6a6-23f5-450d-9fbf-4e2a253d0f43",
   "metadata": {},
   "source": [
    "### Power-Sine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db8dd9-acc7-4574-8eb9-c602b5446943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerSine(Model):\n",
    "    # n_params = 3\n",
    "    # def __init__(self):\n",
    "    #     Model.__init__(self,n_params=self.n_params)\n",
    "    def __init__(self,n_params=3,adam=True,B1_adam=0.9,B2_adam=0.999,eps_adam=1e-8):\n",
    "        Model.__init__(self,n_params=n_params,adam=adam,B1_adam=B1_adam,B2_adam=B2_adam,eps_adam=eps_adam)\n",
    "\n",
    "    def calc_model(self,X):\n",
    "        out = self.params[0,0]*np.fabs(X)**self.params[1,0]*np.sin(X + self.params[2,0])**2\n",
    "        return out # X.shape = (1,n_samp)\n",
    "    \n",
    "    def calc_dmdtheta(self):\n",
    "        # self.X will be available for the data set\n",
    "        arg_sin = self.X[0] + self.params[2,0]\n",
    "        sinx = np.sin(arg_sin)\n",
    "        absx = np.fabs(self.X[0])\n",
    "        absxa1 = absx**self.params[1,0]\n",
    "        dmdtheta = np.zeros((self.n_params,self.X.shape[1])) # (n_params,n_samp)\n",
    "        dmdtheta[0] = absxa1*sinx**2\n",
    "        dmdtheta[1] = self.params[0,0]*dmdtheta[0]*np.log(absx + 1e-20)\n",
    "        dmdtheta[2] = self.params[0,0]*absxa1*np.sin(2*arg_sin)\n",
    "        \n",
    "        return dmdtheta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7ba3e-f0a2-47a8-9901-40388a7c3cc2",
   "metadata": {},
   "source": [
    "### Gaussian mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussMix(Model):\n",
    "    # n_params = 3\n",
    "    # def __init__(self):\n",
    "    #     Model.__init__(self,n_params=self.n_params)\n",
    "    def __init__(self,n_params=3,adam=True,B1_adam=0.9,B2_adam=0.999,eps_adam=1e-8):\n",
    "        Model.__init__(self,n_params=n_params,adam=adam,B1_adam=B1_adam,B2_adam=B2_adam,eps_adam=eps_adam)\n",
    "        # params are (amp,mu,sig^2) for each component\n",
    "        if self.n_params % 3 != 0:\n",
    "            raise ValueError('n_params must be multiple of 3 in GaussMix.')\n",
    "        self.n_comp = self.n_params // 3\n",
    "\n",
    "    def calc_model(self,X):\n",
    "        out = np.zeros_like(X)\n",
    "        for c in range(self.n_comp):\n",
    "            amp,mu,sig2 = self.params[c*3:(c+1)*3,0]\n",
    "            out += amp*np.exp(-0.5*(X-mu)**2/sig2)\n",
    "        return out # X.shape = (1,n_samp)\n",
    "    \n",
    "    def calc_dmdtheta(self):\n",
    "        # self.X will be available for the data set\n",
    "        dmdtheta = np.zeros((self.n_params,self.X.shape[1])) # (n_params,n_samp)\n",
    "        for c in range(self.n_comp):\n",
    "            amp,mu,sig2 = self.params[c*3:(c+1)*3,0]\n",
    "            exp_partarg = (self.X-mu)/sig2\n",
    "            exparg = (self.X-mu)*exp_partarg\n",
    "            exponential = np.exp(-0.5*exparg)\n",
    "            dmdtheta[3*c] = exponential\n",
    "            dmdtheta[3*c+1] = amp*exp_partarg*exponential\n",
    "            dmdtheta[3*c+2] = 0.5*amp/sig2*exparg*exponential\n",
    "        \n",
    "        return dmdtheta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9ce23-d338-499e-a3e5-1b968e507fac",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b3dd8-a6f6-4240-8b54-3b98a966f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Type = 'gm' # 'ps' or 'gm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf33fe1-62e4-43d8-aa00-56827e905e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1983)\n",
    "\n",
    "X_all = np.linspace(-2,4,30)\n",
    "n_samp = X_all.size\n",
    "sigma = np.linspace(0.1,0.3,n_samp)\n",
    "\n",
    "if Model_Type == 'ps':\n",
    "    sigma *= 2.0\n",
    "    N_walker = 10\n",
    "    max_epoch = 50\n",
    "    check_after = 5\n",
    "    mb_count = 3\n",
    "    lrate = 0.1\n",
    "    id_str = 'ps' \n",
    "    model = PowerSine()\n",
    "    model.params[0] = 1\n",
    "    model.params[1] = 1.5\n",
    "    model.params[2] = 0    \n",
    "elif Model_Type == 'gm':\n",
    "    sigma *= 0.5\n",
    "    n_comp = 2\n",
    "    N_walker = 10 if n_comp == 1 else 20\n",
    "    max_epoch = 50 if n_comp == 1 else 100\n",
    "    check_after = 10 if n_comp == 1 else 20\n",
    "    mb_count = 3 #if n_comp == 1 else 3\n",
    "    lrate = 0.1 #if n_comp == 1 else 0.1\n",
    "    id_str = 'gm{0:d}c'.format(n_comp)\n",
    "    model = GaussMix(n_params=3*n_comp)\n",
    "    for c in range(n_comp):\n",
    "        model.params[3*c] = -1 + 3*c # amp(c)\n",
    "        model.params[3*c+1] = -1 + (c+0.5)**2 # mu(c)\n",
    "        model.params[3*c+2] = 4/(c+3)**2 # sig2(c)\n",
    "\n",
    "X_all = model.rv(X_all)\n",
    "n_params = model.n_params\n",
    "invcov_mat = np.diag(1/sigma**2)\n",
    "Y_all_true = model.forward(X_all)\n",
    "Y_all = Y_all_true + sigma*rng.rand(Y_all_true.shape[0],Y_all_true.shape[1])\n",
    "\n",
    "dof = X_all.shape[1] - n_params\n",
    "\n",
    "id_str += '_{0:d}walkers'.format(N_walker) \n",
    "print('id_str:',id_str)\n",
    "file_stem = 'walks/' + id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edaebf0-d717-4063-a400-e19322b84056",
   "metadata": {},
   "outputs": [],
   "source": [
    "Walks_Exist = True\n",
    "\n",
    "if Model_Type == 'ps':\n",
    "    param_mins = [0.5,1,-0.5]\n",
    "    param_maxs = [1.5,2,0.5]\n",
    "    chosen_Model = PowerSine\n",
    "elif Model_Type == 'gm':\n",
    "    param_mins = [-1.5,-1.5,0.1]\n",
    "    param_maxs = [-0.5,0,0.8] if n_comp==1 else [-0.5,0,1.2]\n",
    "    if n_comp > 1:\n",
    "        param_mins = param_mins + [1,0.5,0.05]\n",
    "        param_maxs = param_maxs + [3,2,0.8]\n",
    "    chosen_Model = GaussMix\n",
    "\n",
    "loss_params = {'invcov_mat':invcov_mat}\n",
    "\n",
    "dp = {'N_walker':N_walker,'file_stem':file_stem,'model':chosen_Model,'n_params':n_params,\n",
    "      'param_mins':param_mins,'param_maxs':param_maxs,\n",
    "      'adam':True,'B1_adam':0.9,'B2_adam':0.999,'eps_adam':1e-8,\n",
    "      'X':X_all,'Y':Y_all,'val_frac':0.2,'loss':Chi2,'walks_exist':Walks_Exist,\n",
    "      'seed':None,'verbose':True,'logfile':None,\n",
    "      'max_epoch':max_epoch,'mb_count':mb_count,'lrate':lrate,'loss_params':loss_params,'check_after':check_after}\n",
    "\n",
    "mnt = Mountaineer(data_pack=dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f22e4-6fe0-445a-aca1-e454fbd802d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Walks_Exist:\n",
    "    mnt.climb()\n",
    "walks = mnt.gather()\n",
    "mnt.visualize(walks)\n",
    "data = mnt.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c998768-e510-4514-aab5-c0a5d50eee4d",
   "metadata": {},
   "source": [
    "## Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f027c-ca03-4a8f-b4b9-eb11fb00d08c",
   "metadata": {},
   "source": [
    "### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef0770-86dd-48ed-be73-228dc86cdecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPR_Exists = True\n",
    "CV_Thresh = 0.01 if Model_Type == 'ps' else 1e-3\n",
    "GPR_Dir = 'gpr/stats_'+id_str\n",
    "gprt = GPRTrainer(data_file=mnt.walks_file,tmp_dir=GPR_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e04e96-bf1e-4fdb-9d05-66c600492d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "Kernel = 'rbf' if Model_Type == 'ps' else ('rbf' if n_comp == 1 else 'matern')\n",
    "Max_Iter = 25 if Model_Type == 'ps' else (25 if n_comp == 1 else 50)\n",
    "if GPR_Exists:\n",
    "    interpolator = gprt.train_gpr(verbose=True,vary_kernel=False,kernel=Kernel,skip_train=True)\n",
    "else:\n",
    "    interpolator = gprt.train_gpr(cv_thresh=CV_Thresh,verbose=True,vary_kernel=True,max_iter=Max_Iter,max_iter_vary=Max_Iter//5)\n",
    "gprt.time_this(start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865d62c-98fd-4975-8b25-0e7b70333dd6",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a93662-81f2-487f-8f96-ee1e6e169ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = data[1:,:]\n",
    "Yp = mnt.rv(data[0])\n",
    "\n",
    "Xp.shape,Yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23ffb7-81ea-4ebc-88e2-d5c10e54418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = True\n",
    "FileStem = 'net/NN_'+id_str\n",
    "Val_Frac = 0.25 #if Model_Type == 'ps' else 0.25\n",
    "Seed = 42 #if Model_Type == 'ps' else 42\n",
    "\n",
    "N_L = 3 if Model_Type == 'ps' else (3 if n_comp == 1 else 4)\n",
    "Fac = 5 if Model_Type == 'ps' else (4 if n_comp == 1 else 6)\n",
    "HLay = [Fac*n_params]+[4*Fac*n_params]\n",
    "if N_L == 4:\n",
    "    HLay = HLay + [(Fac//2)*n_params]\n",
    "LRate = 0.05 if Model_Type == 'ps' else 0.005\n",
    "Max_Epoch = 5000 #if Model_Type == 'ps' else (5000 if n_comp == 1 else 15000)\n",
    "Check_After = 50 if Model_Type == 'ps' else Max_Epoch \n",
    "Reg_Fun = 'none' #if Model_Type == 'ps' else 'bn' \n",
    "params_setup = {'data_dim':Xp.shape[0],'L':N_L,'n_layer':HLay+[1],'seed':Seed,'standardize':True,'reg_fun':Reg_Fun,\n",
    "                'atypes':['tanh']*(N_L-1)+['lin'],'loss_type':'square','file_stem':FileStem}\n",
    "params_train = {'lrate':LRate,'max_epoch':Max_Epoch,'mb_count':10,'check_after':Check_After,'val_frac':Val_Frac}    \n",
    "net = Sequential(params_setup)\n",
    "if Train:\n",
    "    start_time = time()\n",
    "    net.train(Xp,Yp,params_train)\n",
    "    net.save()\n",
    "    net.time_this(start_time)\n",
    "else:\n",
    "    net.load()\n",
    "    print ('... done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ccb72-622f-4cb4-a71e-684303914037",
   "metadata": {},
   "source": [
    "## Testing emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482ebdb-810d-4c4b-ba37-9cd4356a3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True loss calculation')\n",
    "start_time = time()\n",
    "Nsamp_ev = 3000\n",
    "Xp_ev = mnt.gen_latin_hypercube(Nsamp=Nsamp_ev,dim=mnt.n_params,param_mins=mnt.param_mins,param_maxs=mnt.param_maxs)\n",
    "Yp_ev = np.zeros((1,Nsamp_ev))\n",
    "loss_params_ev = copy.deepcopy(loss_params)\n",
    "loss_params_ev['Y_full'] = mnt.Y\n",
    "for n in range(Nsamp_ev):\n",
    "    # model.params[:,0] = Xp_ev[n]\n",
    "    model.params[:,0] = Xp_ev[n]\n",
    "    Loss_ev = mnt.loss_module(loss_params_ev)\n",
    "    Yp_ev[0,n] = Loss_ev.forward(model.calc_model(mnt.X))\n",
    "    mnt.status_bar(n,Nsamp_ev)\n",
    "Xp_ev = Xp_ev.T\n",
    "mnt.time_this(start_time)\n",
    "\n",
    "print('NN prediction for loss')\n",
    "start_time = time()\n",
    "Yp_ev_pred_nn = net.predict(Xp_ev)\n",
    "mnt.time_this(start_time)\n",
    "\n",
    "resid_nn = Yp_ev_pred_nn[0]/Yp_ev[0] - 1\n",
    "\n",
    "print('GPR prediction for loss')\n",
    "start_time = time()\n",
    "Yp_ev_pred_gpr = gprt.predict(Xp_ev.T,interpolator)\n",
    "mnt.time_this(start_time)\n",
    "\n",
    "resid_gpr = Yp_ev_pred_gpr/Yp_ev[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07511e1e-ff21-430e-ac8b-f3d5b6d3954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.xlabel('true loss')\n",
    "plt.xlabel('predicted / true - 1')\n",
    "plt.ylim(-1,1)\n",
    "plt.scatter(Yp_ev[0],resid_nn,s=0.8,color='r',label='NN')\n",
    "plt.scatter(Yp_ev[0],resid_gpr,s=0.8,color='b',label='GPR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('true loss')\n",
    "plt.ylabel('predicted loss')\n",
    "plt.plot(np.logspace(0.5,3.5,10),np.logspace(0.5,3.5,10),'k--',lw=1)\n",
    "plt.scatter(Yp_ev[0],Yp_ev_pred_nn[0],s=0.8,color='r',label='NN')\n",
    "plt.scatter(Yp_ev[0],Yp_ev_pred_gpr,s=0.8,color='b',label='GPR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882f42f-58e3-4c06-b99e-ac508047384b",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a8d42-8d2a-4f95-a80f-f8d0c8aa86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Like_Dir = 'likes/'\n",
    "Plots_Dir = 'plots/'\n",
    "\n",
    "Run_Cobaya = True\n",
    "Run_NN = False\n",
    "Run_GPR = False\n",
    "\n",
    "Max_Samples = 1000000\n",
    "Rminus1_Stop = 0.05 \n",
    "Rminus1_CL_Stop = 0.05 # 0.05\n",
    "Rminus1_CL_Level = 0.95 # 95\n",
    "\n",
    "Burn_In = 0\n",
    "\n",
    "if id_str[:2] == 'ps':\n",
    "    Latex_List = ['a_{0}','a_{1}','a_{2}']\n",
    "    Params_List = ['a0','a1','a2']\n",
    "else:\n",
    "    Latex_List = []\n",
    "    Params_List = []\n",
    "    for c in range(n_comp):\n",
    "        Latex_List.append(['A_{'+str(c+1)+'}','\\\\mu_{'+str(c+1)+'}','\\\\sigma^{2}_{'+str(c+1)+'}'])\n",
    "        Params_List.append(['A'+str(c+1),'mu'+str(c+1),'sig2'+str(c+1)])\n",
    "    Latex_List = [item for sublist in Latex_List for item in sublist]\n",
    "    Params_List = [item for sublist in Params_List for item in sublist]\n",
    "\n",
    "info = {}\n",
    "info['params'] = {}\n",
    "info['likelihood'] = {'likelihoods.Chi2Like':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':X_all,'Y':Y_all,'invcov_mat':invcov_mat}}\n",
    "if id_str[:2] == 'ps':\n",
    "    info['theory'] = {'example_likelihoods.PowSineTheory':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':X_all}}\n",
    "    for p in range(len(Params_List)):\n",
    "        ref = 0.5*(param_mins[p] + param_maxs[p])\n",
    "        info['params'][Params_List[p]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                          'prior':{'min':param_mins[p],'max':param_maxs[p]},\n",
    "                                          'proposal':0.01,'latex':Latex_List[p]}\n",
    "else:\n",
    "    info['theory'] = {'example_likelihoods.GaussMixTheory':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':X_all,'n_comp':n_comp}}\n",
    "    for c in range(n_comp):\n",
    "        ref = 0.5*(param_mins[3*c] + param_maxs[3*c])\n",
    "        info['params'][Params_List[3*c]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                              'prior':{'min':param_mins[3*c],'max':param_maxs[3*c]},\n",
    "                                              'proposal':0.01,'latex':Latex_List[3*c]}\n",
    "        ref = 0.5*(param_mins[3*c+1] + param_maxs[3*c+1])\n",
    "        info['params'][Params_List[3*c+1]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                                  'prior':{'min':param_mins[3*c+1],'max':param_maxs[3*c+1]},\n",
    "                                                  'proposal':0.01,'latex':Latex_List[3*c+1]}\n",
    "        ref = 0.5*(param_mins[3*c+2] + param_maxs[3*c+2])\n",
    "        info['params'][Params_List[3*c+2]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                                  'prior':{'min':param_mins[3*c+2],'max':param_maxs[3*c+2]},\n",
    "                                                  'proposal':0.01,'latex':Latex_List[3*c+2]}\n",
    "\n",
    "info['sampler'] = {'mcmc':\n",
    "                   {'learn_proposal': True,\n",
    "                    'Rminus1_single_split': 4,\n",
    "                    'measure_speeds': True,\n",
    "                    'max_samples': Max_Samples,\n",
    "                    'max_tries': 1000,\n",
    "                    'Rminus1_stop': Rminus1_Stop,\n",
    "                    'Rminus1_cl_stop': Rminus1_CL_Stop,\n",
    "                    'Rminus1_cl_level': Rminus1_CL_Level,\n",
    "                    'burn_in': Burn_In}}\n",
    "info_output = 'stats/chains/'+id_str\n",
    "info['output'] = info_output\n",
    "info[\"force\"] = True    \n",
    "\n",
    "info_nn = copy.deepcopy(info)\n",
    "info_nn['likelihood'] = {'likelihoods.EmulLike':\n",
    "                         {'python_path':Like_Dir}}\n",
    "info_nn['theory'] = {'likelihoods.NNTheory':\n",
    "                         {'python_path':Like_Dir,\n",
    "                          'net':net,'keys':Params_List}}\n",
    "info_nn['output'] = info_output+'_nn'\n",
    "\n",
    "info_gpr = copy.deepcopy(info)\n",
    "info_gpr['likelihood'] = {'likelihoods.EmulLike':\n",
    "                             {'python_path':Like_Dir}}\n",
    "info_gpr['theory'] = {'likelihoods.GPRTheory':\n",
    "                         {'python_path':Like_Dir,\n",
    "                          'gprt':gprt,'interpolator':interpolator,'keys':Params_List}}\n",
    "info_gpr['output'] = info_output+'_gpr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0421e-1d3b-4357-9d38-2e178d093b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_Cobaya:\n",
    "    start_time = time()\n",
    "    updated_info, sampler = run(info)\n",
    "    Neval_cobaya = pic.calc_Neval(sampler)\n",
    "    print('Neval_cobaya = {0:d}'.format(Neval_cobaya))\n",
    "    mnt.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44170b-62f4-414d-9342-f2345ad80ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_NN:\n",
    "    start_time = time()\n",
    "    updated_info_nn, sampler_nn = run(info_nn)\n",
    "    Neval_nn = pic.calc_Neval(sampler_nn)\n",
    "    print('Neval_nn = {0:d}'.format(Neval_nn))\n",
    "    mnt.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e90d9-5e92-4547-ac45-3a869b2aa48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_GPR:\n",
    "    start_time = time()\n",
    "    updated_info_gpr, sampler_gpr = run(info_gpr)\n",
    "    Neval_gpr = pic.calc_Neval(sampler_gpr)\n",
    "    print('Neval_gpr = {0:d}'.format(Neval_gpr))\n",
    "    mnt.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312805d0-fddd-49a3-b1a9-0c959f375408",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Fig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2e126-8a9a-46e1-8179-7c2589387548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Burn_Frac = 0.3\n",
    "rng = np.random.RandomState(42)\n",
    "dim = n_params\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "gd_sample = loadMCSamples(os.path.abspath(info[\"output\"]),settings={'ignore_rows':Burn_Frac})\n",
    "gd_sample.label = 'MCMC: {0:d} evals'.format(Neval_cobaya) if Run_Cobaya else 'MCMC'\n",
    "# samples contain params | chi2 | chi2__name | ?? | ??\n",
    "mcmc_covmat = gd_sample.getCovMat().matrix[:dim, :dim]\n",
    "sample = gd_sample.samples\n",
    "sample = sample.T\n",
    "ibest = sample[-2].argmin()\n",
    "mcmc_best = sample[:dim,ibest]\n",
    "mcmc_chi2 = sample[-2,ibest]\n",
    "pval = sysp.gammainc(mcmc_chi2/2,dof/2)\n",
    "mcmc_sig = np.sqrt(np.diag(mcmc_covmat))\n",
    "print('MCMC...')\n",
    "print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params)+','.join(['%.4e' % (pval,) for pval in mcmc_best])+\" )\")\n",
    "print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params)+','.join(['%.4e' % (pval,) for pval in mcmc_sig])+\" )\")\n",
    "print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2,dof,mcmc_chi2/dof,pval))\n",
    "\n",
    "gd_sample_nn = loadMCSamples(os.path.abspath(info_nn[\"output\"]),settings={'ignore_rows':Burn_Frac})\n",
    "gd_sample_nn.label = '     NN: {0:d} evals'.format(Xp.shape[1])\n",
    "# samples contain params | chi2 | chi2__name | ?? | ??\n",
    "mcmc_covmat_nn = gd_sample_nn.getCovMat().matrix[:dim, :dim]\n",
    "sample_nn = gd_sample_nn.samples\n",
    "sample_nn = sample_nn.T\n",
    "ibest_nn = sample_nn[-2].argmin()\n",
    "mcmc_best_nn = sample_nn[:dim,ibest_nn]\n",
    "mcmc_chi2_nn = sample_nn[-2,ibest_nn]\n",
    "pval_nn = sysp.gammainc(mcmc_chi2_nn/2,dof/2)\n",
    "mcmc_sig_nn = np.sqrt(np.diag(mcmc_covmat_nn))\n",
    "print('NN...')\n",
    "print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params)+','.join(['%.4e' % (pval,) for pval in mcmc_best_nn])+\" )\")\n",
    "print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_nn])+\" )\")\n",
    "print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_nn,dof,mcmc_chi2_nn/dof,pval_nn))\n",
    "\n",
    "gd_sample_gpr = loadMCSamples(os.path.abspath(info_gpr[\"output\"]),settings={'ignore_rows':Burn_Frac})\n",
    "gd_sample_gpr.label = '   GPR: {0:d} evals'.format(gprt.pred_var.size)\n",
    "# samples contain params | chi2 | chi2__name | ?? | ??\n",
    "mcmc_covmat_gpr = gd_sample_gpr.getCovMat().matrix[:dim, :dim]\n",
    "sample_gpr = gd_sample_gpr.samples\n",
    "sample_gpr = sample_gpr.T\n",
    "ibest_gpr = sample_gpr[-2].argmin()\n",
    "mcmc_best_gpr = sample_gpr[:dim,ibest_gpr]\n",
    "mcmc_chi2_gpr = sample_gpr[-2,ibest_gpr]\n",
    "pval_gpr = sysp.gammainc(mcmc_chi2_gpr/2,dof/2)\n",
    "mcmc_sig_gpr = np.sqrt(np.diag(mcmc_covmat_gpr))\n",
    "print('GPR...')\n",
    "print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params)+','.join(['%.4e' % (pval,) for pval in mcmc_best_gpr])+\" )\")\n",
    "print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_gpr])+\" )\")\n",
    "print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_gpr,dof,mcmc_chi2_gpr/dof,pval_gpr))\n",
    "\n",
    "plot_param_list = Params_List\n",
    "Subplot_Size = 1.6 \n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter(subplot_size=Subplot_Size)\n",
    "gdplot.settings.num_plot_contours = 3\n",
    "gdplot.settings.axes_fontsize = FS3\n",
    "gdplot.settings.axes_labelsize = FS2\n",
    "gdplot.settings.title_limit_fontsize = FS3\n",
    "\n",
    "gdplot.triangle_plot([gd_sample,gd_sample_nn,gd_sample_gpr], plot_param_list,\n",
    "                     filled=[True,True,True],contour_colors=['indigo','crimson','darkgreen'],legend_loc='upper right',\n",
    "                     title_limit=0)\n",
    "for par_y in range(dim):\n",
    "    str_y = plot_param_list[par_y]\n",
    "    ax = gdplot.subplots[par_y,par_y]\n",
    "    ax.axvline(mcmc_best[par_y],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "    ax.axvline(mcmc_best_nn[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "    ax.axvline(mcmc_best_gpr[par_y],c='darkgreen',ls='--',lw=1,alpha=0.6)\n",
    "    for par_x in range(par_y):\n",
    "        str_x = plot_param_list[par_x]\n",
    "        #print(par_x,par_y,':',str_x,str_y)\n",
    "        ax = gdplot.subplots[par_y,par_x]\n",
    "        ax.scatter([mcmc_best[par_x]],[mcmc_best[par_y]],marker='*',s=50,c='aliceblue')\n",
    "        ax.scatter([mcmc_best_nn[par_x]],[mcmc_best_nn[par_y]],marker='*',s=50,c='peachpuff')\n",
    "        ax.scatter([mcmc_best_gpr[par_x]],[mcmc_best_gpr[par_y]],marker='*',s=50,c='lightcyan')\n",
    "        ax.axvline(mcmc_best[par_x],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "        ax.axhline(mcmc_best[par_y],c='indigo',ls='--',lw=1.5,alpha=0.6)\n",
    "        ax.axvline(mcmc_best_nn[par_x],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "        ax.axhline(mcmc_best_nn[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "        ax.axvline(mcmc_best_gpr[par_x],c='darkgreen',ls='--',lw=1,alpha=0.6)\n",
    "        ax.axhline(mcmc_best_gpr[par_y],c='darkgreen',ls='--',lw=1,alpha=0.6)\n",
    "\n",
    "if Save_Fig:\n",
    "    filename = 'contours_'+id_str+'.png'\n",
    "    print('Writing to file: '+Plots_Dir+filename)\n",
    "    gdplot.export(fname=filename,adir=Plots_Dir)\n",
    "\n",
    "mnt.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09a274-ba0e-4137-95cc-86e306b4b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC\n",
    "start_time = time()\n",
    "model.params = mnt.cv(mcmc_best[:dim])\n",
    "model_best = model.forward(mnt.X)[0]\n",
    "\n",
    "N_Boot_Cobaya = np.min([1000,int(0.2*sample[0].size)])\n",
    "Ind = gd_sample.random_single_samples_indices(random_state=42,max_samples=N_Boot_Cobaya)\n",
    "N_Boot_Cobaya = Ind.size\n",
    "print('N_Boot_Cobaya: ',N_Boot_Cobaya)\n",
    "\n",
    "model_boot = np.zeros((N_Boot_Cobaya,n_samp),dtype=float)\n",
    "\n",
    "print('... extracting stats from subsample')\n",
    "for b in range(N_Boot_Cobaya):\n",
    "    params_b = sample[:dim,Ind[b]] \n",
    "    model.params = mnt.cv(params_b[:dim])\n",
    "    model_boot[b] = model.forward(mnt.X)[0]\n",
    "    mnt.status_bar(b,N_Boot_Cobaya)\n",
    "\n",
    "model_16pc = np.percentile(model_boot,16,axis=0)\n",
    "model_84pc = np.percentile(model_boot,84,axis=0)\n",
    "\n",
    "# NN\n",
    "model.params = mnt.cv(mcmc_best_nn[:dim])\n",
    "model_best_nn = model.forward(mnt.X)[0]\n",
    "\n",
    "N_Boot_NN = np.min([1000,int(0.2*sample_nn[0].size)])\n",
    "Ind_nn = gd_sample_nn.random_single_samples_indices(random_state=42,max_samples=N_Boot_NN)\n",
    "N_Boot_NN = Ind_nn.size\n",
    "print('N_Boot_NN: ',N_Boot_NN)\n",
    "\n",
    "model_boot_nn = np.zeros((N_Boot_NN,n_samp),dtype=float)\n",
    "\n",
    "print('... extracting stats from subsample')\n",
    "for b in range(N_Boot_NN):\n",
    "    params_b = sample_nn[:dim,Ind_nn[b]] \n",
    "    model.params = mnt.cv(params_b[:dim])\n",
    "    model_boot_nn[b] = model.forward(mnt.X)[0]\n",
    "    mnt.status_bar(b,N_Boot_NN)\n",
    "\n",
    "model_16pc_nn = np.percentile(model_boot_nn,16,axis=0)\n",
    "model_84pc_nn = np.percentile(model_boot_nn,84,axis=0)\n",
    "\n",
    "# GPR\n",
    "model.params = mnt.cv(mcmc_best_gpr[:dim])\n",
    "model_best_gpr = model.forward(mnt.X)[0]\n",
    "\n",
    "N_Boot_GPR = np.min([1000,int(0.2*sample_gpr[0].size)])\n",
    "Ind_gpr = gd_sample_gpr.random_single_samples_indices(random_state=42,max_samples=N_Boot_GPR)\n",
    "N_Boot_GPR = Ind_gpr.size\n",
    "print('N_Boot_GPR: ',N_Boot_GPR)\n",
    "\n",
    "model_boot_gpr = np.zeros((N_Boot_GPR,n_samp),dtype=float)\n",
    "\n",
    "print('... extracting stats from subsample')\n",
    "for b in range(N_Boot_GPR):\n",
    "    params_b = sample_gpr[:dim,Ind_gpr[b]] \n",
    "    model.params = mnt.cv(params_b[:dim])\n",
    "    model_boot_gpr[b] = model.forward(mnt.X)[0]\n",
    "    mnt.status_bar(b,N_Boot_GPR)\n",
    "\n",
    "model_16pc_gpr = np.percentile(model_boot_gpr,16,axis=0)\n",
    "model_84pc_gpr = np.percentile(model_boot_gpr,84,axis=0)\n",
    "\n",
    "del model_boot,model_boot_nn,model_boot_gpr\n",
    "gc.collect()\n",
    "\n",
    "cols = ['indigo','crimson','darkgreen']\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "if Model_Type == 'ps':\n",
    "    plt.ylim(-1,6)\n",
    "else:\n",
    "    if n_comp == 1:\n",
    "        plt.ylim(-1.5,1)\n",
    "    else:\n",
    "        plt.ylim(-1.5,3)\n",
    "plt.plot(mnt.X[0],model_best,'-',lw=1,c=cols[0],label='MCMC')\n",
    "plt.fill_between(mnt.X[0],model_84pc,model_16pc,color=cols[0],alpha=0.15)\n",
    "plt.plot(mnt.X[0],model_best_nn,'-',lw=1,c=cols[1],label='NN')\n",
    "plt.fill_between(mnt.X[0],model_84pc_nn,model_16pc_nn,color=cols[1],alpha=0.15)\n",
    "plt.plot(mnt.X[0],model_best_gpr,'-',lw=1,c=cols[2],label='GPR')\n",
    "plt.fill_between(mnt.X[0],model_84pc_gpr,model_16pc_gpr,color=cols[2],alpha=0.15)\n",
    "\n",
    "plt.errorbar(mnt.X[0],mnt.Y[0],yerr=sigma,c='k',ls='none',capsize=5,marker='o',markersize=4,label='data')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.minorticks_on()\n",
    "if Save_Fig:\n",
    "    filename = Plots_Dir+'stats_'+id_str+'.png'\n",
    "    print('Writing to file: '+filename)\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "mnt.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c13ad2-e14f-4ca4-b9db-761b23093ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d6bb5-1f01-4427-9d8e-679181e615a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build = True\n",
    "\n",
    "# Train_Frac = 0.8\n",
    "# Val_Frac = 0.1\n",
    "# Min_Layer = 2\n",
    "# Max_Layer = 2\n",
    "# Max_Ex = 2*n_params\n",
    "# TTL = 1e-5\n",
    "# Loss_Type = 'square'\n",
    "# Seed = None\n",
    "# FileStem = 'net/NN_'+id_str\n",
    "\n",
    "# bnn = BuildNN(Xp,Yp,train_frac=Train_Frac,val_frac=Val_Frac,min_layer=Min_Layer,max_layer=Max_Layer,max_ex=Max_Ex,\n",
    "#               target_test_loss=TTL,loss_type=Loss_Type,seed=Seed,file_stem=FileStem)\n",
    "# if Build:\n",
    "#     start_time = time()\n",
    "#     net,params_train,mtl = bnn.trainNN()\n",
    "#     print('Best mean test loss = {0:.3e}'.format(mtl))\n",
    "#     print('Setup params: ',net.params)\n",
    "#     print('Training params: ',params_train)\n",
    "#     bnn.time_this(start_time)\n",
    "# else:\n",
    "#     net = bnn.load()\n",
    "#     print('Loaded network with')\n",
    "#     print('...    setup params: ',net.params)\n",
    "#     params_train = bnn.load_train()\n",
    "#     print('... training params: ',params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64086eb8-32e9-4efc-bead-89ba9c092052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Build:\n",
    "#     plt.figure(figsize=(7,7))\n",
    "#     plt.xlim(0.5,params_train['max_epoch'])\n",
    "#     plt.ylim(1e0,1e7)\n",
    "#     plt.yscale('log')\n",
    "#     plt.xscale('log')\n",
    "#     nn_label = '{0:1d}-layer NN'.format(net.L)\n",
    "#     # bn_label = '{0:1d}-layer NN with BatchNorm'.format(net.L)\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.ylabel('loss')\n",
    "#     plt.plot(net.epochs,net.epoch_loss,'k-',lw=0.5,label=nn_label+': train')\n",
    "#     plt.plot(net.epochs,net.val_loss,'r-',lw=0.5,label=nn_label+': val')\n",
    "#     # plt.plot(net_bn.epochs,net_bn.epoch_loss,'r-',lw=0.5,label=bn_label)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     print(net.epoch_loss[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
